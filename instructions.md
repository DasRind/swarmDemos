# ğŸœ Ant Colony Simulation â€“ Swarm Robotics Demo

## ğŸ¯ Ziel

Diese Demo visualisiert das Prinzip der **Schwarmintelligenz** am Beispiel einer **Ameisenkolonie**.  
Mehrere virtuelle Ameisen suchen nach Futter, kommunizieren indirekt Ã¼ber **Pheromonspuren** und bilden dadurch **emergente Pfade** zwischen Nest und Futterquellen â€“ ganz ohne zentrale Steuerung.

---

## ğŸ’¡ KonzeptÃ¼berblick

- **Technologie:** Angular + TypeScript + HTML Canvas
- **Darstellung:** 2D-Simulation auf Canvas
- **Steuerung:** UI mit Eingabefeldern, Buttons und Slidern
- **Interaktion:** Nutzer kann Futterquellen wÃ¤hrend der Simulation hinzufÃ¼gen
- **Simulation:** basiert auf lokaler Wahrnehmung, PheromonintensitÃ¤t und Zufallsentscheidungen

---

## âš™ï¸ Hauptfunktionen

### 1. Eingabefeld fÃ¼r Ameisenanzahl

- Der Nutzer kann die Anzahl der Ameisen (z. B. 10â€“500) einstellen.
- Ã„nderungen wirken beim Start der Simulation.

### 2. Start/Stop/Reset-Buttons

- **Start:** initialisiert und startet die Simulation
- **Stop:** pausiert die Simulation
- **Reset:** setzt alle Daten (Ameisen, Pheromone, Futter) zurÃ¼ck

### 3. Futter hinzufÃ¼gen

- Zwei Varianten:
  - **Drag & Drop:** Futter-Icon aus einer Palette auf das Canvas ziehen
  - **Klick-Platzierung:** Futter-Icon anklicken, dann im Canvas klicken
- Mehrere Futterquellen gleichzeitig mÃ¶glich
- Quellen sind wÃ¤hrend der Simulation dynamisch Ã¤nderbar

### 4. Futterabbau (Depletion)

- Per Toggle-Button aktivierbar
- Futtermenge sinkt passiv mit der Zeit oder schneller, wenn Ameisen es finden
- Bei ErschÃ¶pfung verschwindet die Futterquelle automatisch

### 5. Zeitskalierung (Simulation Speed)

- Slider zur Steuerung der Simulationsgeschwindigkeit (z. B. 0.1Ã— â€“ 4Ã—)
- 1 Schritt entspricht standardmÃ¤ÃŸig **0.1 Sekunden**
- Geschwindigkeit wirkt direkt auf Bewegung, Verdunstung und Entscheidungszyklen

### 6. Koordinatensystem & Skalierung

- Welt in **World Units (WU)** statt Pixel
- Canvas wird automatisch an BildschirmgrÃ¶ÃŸe angepasst
- Funktionen:
  - `worldToScreen()` â†’ Koordinatenumrechnung
  - `screenToWorld()` â†’ Mausposition auf Welt umrechnen
- Optional: Zoom & Pan-Funktion fÃ¼r bessere Ãœbersicht

---

## ğŸ§© Zentrale Simulationselemente

### ğŸ  Nest

- Fester Punkt in der Mitte des Canvas
- Start- und RÃ¼ckkehrort der Ameisen

### ğŸ Futterquelle

- Position frei platzierbar
- Radius definiert Suchreichweite
- EnthÃ¤lt eine KapazitÃ¤t (Futtermenge)
- Menge verringert sich durch AmeisenaktivitÃ¤t oder Ã¼ber Zeit

### ğŸœ Ameise

- Eigenschaften:
  - Position `(x, y)`
  - Richtung `dir`
  - Zustand: `carryingFood: boolean`
  - Geschwindigkeit in WU/s
- Verhalten:
  1. LÃ¤uft zufÃ¤llig umher, solange kein Futter gefunden
  2. Erkennt Futter â†’ nimmt es auf â†’ kehrt zum Nest zurÃ¼ck
  3. Legt auf RÃ¼ckweg Pheromone ab
  4. Im Nest angekommen â†’ Futter abgeben â†’ erneut auf Futtersuche gehen

### ğŸ’¨ Pheromone

- Unsichtbare oder als Heatmap dargestellte Spuren
- Wertebereich **0â€“1** (IntensitÃ¤t)
- Verdunsten Ã¼ber Zeit (Abnahme pro Sekunde)
- HÃ¤ufig benutzte Wege werden durch Wiederholung verstÃ¤rkt

---

## ğŸ§­ Entscheidungslogik der Ameisen

- Jede Ameise orientiert sich an der **lokalen Pheromonkonzentration**.
- Entscheidung erfolgt **probabilistisch** (nicht deterministisch).

**Grundregel (vereinfacht):**

```
if (PheromonstÃ¤rke > Schwellenwert)
   -> Richtung leicht anpassen zur stÃ¤rksten Spur
else
   -> zufÃ¤llige Bewegung
```

**Parameter:**

- `Î±` â†’ StÃ¤rke des Einflusses von Pheromonen (**Exploitation**)
- `Î²` â†’ StÃ¤rke des Zufallsanteils (**Exploration**)

**Interpretation:**

- Hoher Î± â†’ folgt stÃ¤rker bestehenden Spuren â†’ stabil, aber unflexibel
- Niedriger Î± â†’ mehr Zufall â†’ explorativer, aber langsamer
- Balance zwischen beiden fÃ¼hrt zu optimalem Verhalten

---

## ğŸ” Simulationsablauf

### 1. Initialisierung

- Nest in der Mitte, definierte WeltgrÃ¶ÃŸe (z. B. 100Ã—60 WU)
- Ameisen starten im Nest
- Futterquellen initial vorhanden oder vom Nutzer platziert

### 2. Simulationsschleife (alle 100 ms)

1. Bewegung der Ameisen
2. Entscheidung (Pheromon folgen oder Zufall)
3. Ablage und Verdunstung von Pheromonen
4. PrÃ¼fung auf Futter oder Nest
5. Futterabbau (wenn aktiviert)
6. Zeitfaktor aus Slider anwenden

### 3. Rendering

- Canvas wird pro Frame neu gezeichnet
- Elemente: Nest, Futter, Ameisen, ggf. Pheromon-Heatmap
- Anzeige bleibt unabhÃ¤ngig von BildschirmgrÃ¶ÃŸe lesbar

---

## ğŸ–±ï¸ Benutzerinteraktionen

| Aktion                             | Beschreibung                          |
| ---------------------------------- | ------------------------------------- |
| **Eingabe â€Ameisenanzahlâ€œ**        | Bestimmt Startpopulation              |
| **Start**                          | Simulation initialisieren und starten |
| **Stop**                           | Simulation pausieren                  |
| **Reset**                          | Alles zurÃ¼cksetzen                    |
| **Futter-Drag&Drop**               | Quelle auf Canvas hinzufÃ¼gen          |
| **Klick im Canvas (nach Auswahl)** | Futterquelle platzieren               |
| **Futterabbau-Toggle**             | Aktiviert/Deaktiviert Depletion       |
| **Simulationsgeschwindigkeit**     | Steuerung Ã¼ber Slider                 |

---

## ğŸ“ˆ Live-Parameter (Ã¤nderbar wÃ¤hrend Laufzeit)

- Î± (PheromonabhÃ¤ngigkeit)
- Î² (Zufallsanteil)
- Verdunstungsrate
- Ameisengeschwindigkeit
- Zeitskalierung (0.1Ã— â€“ 4Ã—)
- Futterabbau an/aus

---

## ğŸ§  Didaktischer Fokus

Die Demo soll zeigen:

- **Selbstorganisation** ohne zentrale Kontrolle
- **Balance zwischen Zufall und Struktur**
- **Lernen durch RÃ¼ckkopplung** (VerstÃ¤rkung erfolgreicher Wege)
- **Vergessen durch Verdunstung** (Anpassung an neue Situationen)
- **Kollektives Verhalten** aus einfachen Regeln

> â€Jede Ameise ist dumm â€“ aber der Schwarm ist intelligent.â€œ

---

## ğŸ“š Erweiterbare Ideen

- Hindernisse oder Labyrinthe (z. B. Double-Bridge-Experiment)
- Mehrere Futterquellen mit unterschiedlicher Entfernung
- Heatmap-Overlay zur Visualisierung von Pheromonen
- Statistik-Panel mit:
  - Anzahl transportierter Futtereinheiten
  - Aktive Pfade
  - Durchschnittliche PfadlÃ¤nge
- Zoom- und Pan-Funktion
- Presets fÃ¼r verschiedene Verhaltensmodi:
  - _Exploration-heavy_
  - _Exploitation-heavy_
  - _Balanced_

---

## âœ… Zusammenfassung

Diese Simulation zeigt, dass:

- **Einfache lokale Regeln** komplexes Verhalten erzeugen
- **Zufall** kein Fehler, sondern ein Lernmechanismus ist
- **RÃ¼ckkopplung** (VerstÃ¤rkung + Verdunstung) zu kollektiver Intelligenz fÃ¼hrt
- **KÃ¼rzeste Wege** emergent entstehen, ohne dass jemand sie plant

> **â€Intelligenz entsteht nicht im Individuum, sondern in der Interaktion.â€œ**
